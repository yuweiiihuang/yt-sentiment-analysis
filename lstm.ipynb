{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T17:13:10.989571Z",
     "iopub.status.busy": "2025-12-09T17:13:10.989034Z",
     "iopub.status.idle": "2025-12-09T17:13:11.013665Z",
     "shell.execute_reply": "2025-12-09T17:13:11.013096Z",
     "shell.execute_reply.started": "2025-12-09T17:13:10.989553Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x77a98a38f430>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Using the GPU: NVIDIA GeForce GTX 1060 6GB\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('Using the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T17:13:11.015927Z",
     "iopub.status.busy": "2025-12-09T17:13:11.015236Z",
     "iopub.status.idle": "2025-12-09T17:13:11.101949Z",
     "shell.execute_reply": "2025-12-09T17:13:11.101278Z",
     "shell.execute_reply.started": "2025-12-09T17:13:11.015909Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Comment Sentiment\n",
      "0  it’s so adorable that he says “baap” for up an...  positive\n",
      "1  sir i have no words to describe your teaching ...  positive\n",
      "2  the reason they said large and open space inst...   neutral\n",
      "3  for ur information this is an fact that jrntr ...   neutral\n",
      "4  you can really tell the progress awesome espec...  positive\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14691 entries, 0 to 14690\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Comment    14691 non-null  object\n",
      " 1   Sentiment  14691 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 229.7+ KB\n",
      "None\n",
      "Sentiment\n",
      "positive    9121\n",
      "neutral     3700\n",
      "negative    1870\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA_PATH = \"dataset/processed/train.csv\"\n",
    "train_df = pd.read_csv(TRAIN_DATA_PATH)\n",
    "\n",
    "print(train_df.head())\n",
    "print(train_df.info())\n",
    "print(train_df['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Comment Sentiment\n",
      "0  “oh my god guys there’s an octopus eating a cr...  negative\n",
      "1  my daughter will be starting her 8th grade che...  positive\n",
      "2  for some future video you should definitely bu...   neutral\n",
      "3  i’m chronically ill and very frequently find i...  positive\n",
      "4  the pizza planet pizza being awful is just dis...  negative\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3673 entries, 0 to 3672\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Comment    3673 non-null   object\n",
      " 1   Sentiment  3673 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 57.5+ KB\n",
      "None\n",
      "Sentiment\n",
      "positive    2281\n",
      "neutral      925\n",
      "negative     467\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "TEST_DATA_PATH = \"dataset/processed/test.csv\"\n",
    "test_df = pd.read_csv(TEST_DATA_PATH)\n",
    "\n",
    "print(test_df.head())\n",
    "print(test_df.info())\n",
    "print(test_df['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T17:13:11.102856Z",
     "iopub.status.busy": "2025-12-09T17:13:11.102677Z",
     "iopub.status.idle": "2025-12-09T17:13:13.542777Z",
     "shell.execute_reply": "2025-12-09T17:13:13.542142Z",
     "shell.execute_reply.started": "2025-12-09T17:13:11.102843Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/yuweihuang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/yuweihuang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "keep_words = {\n",
    "    \"not\", \"no\", \"nor\",\n",
    "    \"don't\", \"didn't\", \"doesn't\",\n",
    "    \"isn't\", \"wasn't\", \"aren't\", \"weren't\",\n",
    "    \"can't\", \"couldn't\", \"won't\", \"wouldn't\",\n",
    "    \"shouldn't\", \"haven't\", \"hasn't\", \"hadn't\"\n",
    "}\n",
    "\n",
    "\n",
    "stop_words = stop_words - keep_words\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \" \", text)\n",
    "    text = re.sub(r\"\\d+\", \" \", text)\n",
    "    # tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "train_df['clean_comment'] = train_df['Comment'].astype(str).apply(clean_text)\n",
    "test_df['clean_comment'] = test_df['Comment'].astype(str).apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 切 train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T17:13:13.544911Z",
     "iopub.status.busy": "2025-12-09T17:13:13.544499Z",
     "iopub.status.idle": "2025-12-09T17:13:13.572099Z",
     "shell.execute_reply": "2025-12-09T17:13:13.571499Z",
     "shell.execute_reply.started": "2025-12-09T17:13:13.544891Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 11752\n",
      "Val size: 2939\n"
     ]
    }
   ],
   "source": [
    "TEXT_COL = \"clean_comment\"   \n",
    "LABEL_COL = \"Sentiment\"\n",
    "\n",
    "X = train_df[TEXT_COL]\n",
    "y = train_df[LABEL_COL]\n",
    "\n",
    "# label -> int\n",
    "le = LabelEncoder()\n",
    "y_int = le.fit_transform(y)\n",
    "\n",
    "# 從 train_val 切 validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y_int,\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    "    stratify=y_int\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(X_train))\n",
    "print(\"Val size:\", len(X_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size: 3673\n",
      "                                                text  label_int     label\n",
      "0  “ oh god guys ’ octopus eating crab ” watches ...          0  negative\n",
      "1  daughter starting th grade chem section next w...          2  positive\n",
      "2  future video definitely build like huge base o...          1   neutral\n",
      "3  ’ chronically ill frequently find difficult ea...          2  positive\n",
      "4  pizza planet pizza awful disney sticking bit s...          0  negative\n"
     ]
    }
   ],
   "source": [
    "X_test = test_df[TEXT_COL]\n",
    "y_test = le.transform(test_df[LABEL_COL])\n",
    "\n",
    "print(\"Test size:\", len(X_test))\n",
    "\n",
    "# test 前五筆\n",
    "preview = pd.DataFrame({\n",
    "    \"text\": X_test.head().values,\n",
    "    \"label_int\": y_test[:5],\n",
    "    \"label\": le.inverse_transform(y_test[:5])\n",
    "})\n",
    "print(preview)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T17:13:13.573036Z",
     "iopub.status.busy": "2025-12-09T17:13:13.572838Z",
     "iopub.status.idle": "2025-12-09T17:13:13.580460Z",
     "shell.execute_reply": "2025-12-09T17:13:13.579751Z",
     "shell.execute_reply.started": "2025-12-09T17:13:13.573020Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 2.6185383244206775, 1: 1.3234234234234235, 2: 0.5369152046783626}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# y_train label (0/1/2)\n",
    "classes = np.unique(y_train)\n",
    "\n",
    "class_weights_arr = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=classes,\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "class_weights = dict(zip(classes, class_weights_arr))\n",
    "print(\"Class weights:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer + padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T17:13:13.581357Z",
     "iopub.status.busy": "2025-12-09T17:13:13.581110Z",
     "iopub.status.idle": "2025-12-09T17:13:14.189419Z",
     "shell.execute_reply": "2025-12-09T17:13:14.188809Z",
     "shell.execute_reply.started": "2025-12-09T17:13:13.581304Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "max_words = 20000   \n",
    "max_len   = 150     \n",
    "\n",
    "class SimpleTokenizer:\n",
    "    def __init__(self, num_words, oov_token=\"<OOV>\"):\n",
    "        self.num_words = num_words\n",
    "        self.oov_token = oov_token\n",
    "        self.word_index = {}\n",
    "        self.index_word = {}\n",
    "\n",
    "    def fit_on_texts(self, texts):\n",
    "        counter = Counter()\n",
    "        for text in texts:\n",
    "            counter.update(text.split())\n",
    "        vocab = counter.most_common(self.num_words - 1)  # reserve 0 for padding, 1 for OOV\n",
    "        self.word_index = {self.oov_token: 1}\n",
    "        idx = 2\n",
    "        for word, _ in vocab:\n",
    "            if idx >= self.num_words:\n",
    "                break\n",
    "            self.word_index[word] = idx\n",
    "            idx += 1\n",
    "        self.index_word = {idx: word for word, idx in self.word_index.items()}\n",
    "\n",
    "    def texts_to_sequences(self, texts):\n",
    "        seqs = []\n",
    "        for text in texts:\n",
    "            seq = []\n",
    "            for word in text.split():\n",
    "                idx = self.word_index.get(word)\n",
    "                if idx is None or idx >= self.num_words:\n",
    "                    idx = self.word_index[self.oov_token]\n",
    "                seq.append(idx)\n",
    "            seqs.append(seq)\n",
    "        return seqs\n",
    "\n",
    "def pad_sequences_custom(seqs, maxlen, padding='post', truncating='post'):\n",
    "    padded = np.zeros((len(seqs), maxlen), dtype=np.int64)\n",
    "    for i, seq in enumerate(seqs):\n",
    "        if len(seq) > maxlen:\n",
    "            trunc = seq[-maxlen:] if truncating == 'pre' else seq[:maxlen]\n",
    "        else:\n",
    "            trunc = seq\n",
    "        if padding == 'pre':\n",
    "            padded[i, -len(trunc):] = trunc\n",
    "        else:\n",
    "            padded[i, :len(trunc)] = trunc\n",
    "    return padded\n",
    "\n",
    "tokenizer = SimpleTokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "def texts_to_padded(texts):\n",
    "    seqs = tokenizer.texts_to_sequences(texts)\n",
    "    return pad_sequences_custom(seqs, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "X_train_pad = texts_to_padded(X_train)\n",
    "X_val_pad   = texts_to_padded(X_val)\n",
    "X_test_pad  = texts_to_padded(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T17:13:14.190407Z",
     "iopub.status.busy": "2025-12-09T17:13:14.190134Z",
     "iopub.status.idle": "2025-12-09T17:13:14.230664Z",
     "shell.execute_reply": "2025-12-09T17:13:14.230123Z",
     "shell.execute_reply.started": "2025-12-09T17:13:14.190380Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "lstm_units = 128\n",
    "dense_units = 64\n",
    "num_classes = len(le.classes_)\n",
    "vocab_size = max_words\n",
    "\n",
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, dense_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, dense_dim)\n",
    "        self.fc2 = nn.Linear(dense_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)\n",
    "        _, (h, _) = self.lstm(emb)\n",
    "        h_cat = torch.cat((h[-2], h[-1]), dim=1)  # concat both directions\n",
    "        x = torch.relu(self.fc1(h_cat))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "model = BiLSTMClassifier(vocab_size, embedding_dim, lstm_units, dense_units, num_classes).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "BiLSTMClassifier                         [1, 150]                  [1, 3]                    --\n",
       "├─Embedding: 1-1                         [1, 150]                  [1, 150, 256]             5,120,000\n",
       "├─LSTM: 1-2                              [1, 150, 256]             [1, 150, 256]             395,264\n",
       "├─Linear: 1-3                            [1, 256]                  [1, 64]                   16,448\n",
       "├─Dropout: 1-4                           [1, 64]                   [1, 64]                   --\n",
       "├─Linear: 1-5                            [1, 64]                   [1, 3]                    195\n",
       "===================================================================================================================\n",
       "Total params: 5,531,907\n",
       "Trainable params: 5,531,907\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 64.43\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.61\n",
       "Params size (MB): 22.13\n",
       "Estimated Total Size (MB): 22.74\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(\n",
    "    model,\n",
    "    input_size=(1, max_len),      # batch, seq_len\n",
    "    dtypes=[torch.long],\n",
    "    col_names=(\"input_size\", \"output_size\", \"num_params\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_tensor = torch.tensor(\n",
    "    [class_weights.get(i, 1.0) for i in range(num_classes)],\n",
    "    dtype=torch.float32,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_ds = TensorDataset(\n",
    "    torch.tensor(X_train_pad, dtype=torch.long),\n",
    "    torch.tensor(y_train, dtype=torch.long)\n",
    ")\n",
    "val_ds = TensorDataset(\n",
    "    torch.tensor(X_val_pad, dtype=torch.long),\n",
    "    torch.tensor(y_val, dtype=torch.long)\n",
    ")\n",
    "test_ds = TensorDataset(torch.tensor(X_test_pad, dtype=torch.long))\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=batch_size)\n",
    "test_dl = DataLoader(test_ds, batch_size=256)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T17:13:14.231551Z",
     "iopub.status.busy": "2025-12-09T17:13:14.231286Z",
     "iopub.status.idle": "2025-12-09T17:13:36.729665Z",
     "shell.execute_reply": "2025-12-09T17:13:36.729099Z",
     "shell.execute_reply.started": "2025-12-09T17:13:14.231530Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=1.0450, val_loss=0.9788, val_acc=0.4750\n",
      "Epoch 2: train_loss=0.8786, val_loss=0.8903, val_acc=0.6257\n",
      "Epoch 3: train_loss=0.6367, val_loss=0.8711, val_acc=0.6444\n",
      "Epoch 4: train_loss=0.3895, val_loss=1.0260, val_acc=0.6870\n",
      "Epoch 5: train_loss=0.2074, val_loss=1.1934, val_acc=0.6689\n",
      "Epoch 6: train_loss=0.1152, val_loss=1.5156, val_acc=0.6897\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "patience = 3\n",
    "best_val = float(\"inf\")\n",
    "wait = 0\n",
    "\n",
    "MODEL_PATH = \"outputs/lstm/best_lstm.pt\"\n",
    "os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "    for xb, yb in train_dl:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(xb)\n",
    "        loss = criterion(out, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_train_loss += loss.item() * xb.size(0)\n",
    "\n",
    "    train_loss = running_train_loss / len(train_ds)\n",
    "\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_dl:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            out = model(xb)\n",
    "            loss = criterion(out, yb)\n",
    "            running_val_loss += loss.item() * xb.size(0)\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct += (pred == yb).sum().item()\n",
    "            total += yb.size(0)\n",
    "\n",
    "    val_loss = running_val_loss / len(val_ds)\n",
    "    val_acc = correct / total\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, val_acc={val_acc:.4f}\")\n",
    "\n",
    "    if val_loss < best_val:\n",
    "        best_val = val_loss\n",
    "        wait = 0\n",
    "        torch.save(model.state_dict(), MODEL_PATH)\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= patience:\n",
    "            print(\"Early stopping\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test set 預測 + 存CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMClassifier(\n",
       "  (embedding): Embedding(20000, 256, padding_idx=0)\n",
       "  (lstm): LSTM(256, 128, batch_first=True, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T17:13:36.730862Z",
     "iopub.status.busy": "2025-12-09T17:13:36.730656Z",
     "iopub.status.idle": "2025-12-09T17:13:37.455230Z",
     "shell.execute_reply": "2025-12-09T17:13:37.454643Z",
     "shell.execute_reply.started": "2025-12-09T17:13:36.730846Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "probas = []\n",
    "with torch.no_grad():\n",
    "    for (xb,) in test_dl:\n",
    "        xb = xb.to(device)\n",
    "        out = model(xb)\n",
    "        probas.append(torch.softmax(out, dim=1).cpu())\n",
    "\n",
    "y_test_proba = torch.cat(probas, dim=0).numpy()\n",
    "y_test_pred  = np.argmax(y_test_proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T17:13:37.456276Z",
     "iopub.status.busy": "2025-12-09T17:13:37.456022Z",
     "iopub.status.idle": "2025-12-09T17:13:37.469188Z",
     "shell.execute_reply": "2025-12-09T17:13:37.468603Z",
     "shell.execute_reply.started": "2025-12-09T17:13:37.456257Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({\n",
    "    \"id\": X_test.index,\n",
    "    \"comment\": test_df.loc[X_test.index, \"Comment\"].values,\n",
    "    \"true_label\": y_test.astype(int),\n",
    "    \"pred_label\": y_test_pred.astype(int),\n",
    "})\n",
    "\n",
    "label_to_id = {cls: idx for idx, cls in enumerate(le.classes_)}\n",
    "for idx, cls in enumerate(le.classes_):\n",
    "    pred_df[f\"prob_{label_to_id[cls]}\"] = y_test_proba[:, idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T17:13:37.470169Z",
     "iopub.status.busy": "2025-12-09T17:13:37.469917Z",
     "iopub.status.idle": "2025-12-09T17:13:37.500582Z",
     "shell.execute_reply": "2025-12-09T17:13:37.499849Z",
     "shell.execute_reply.started": "2025-12-09T17:13:37.470140Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to outputs/lstm/test_predictions_rs42.csv\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_CSV = f\"outputs/lstm/test_predictions_rs{SEED}.csv\"\n",
    "os.makedirs(os.path.dirname(OUTPUT_CSV), exist_ok=True)\n",
    "pred_df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(\"Saved to\", OUTPUT_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-09T17:13:37.501425Z",
     "iopub.status.busy": "2025-12-09T17:13:37.501233Z",
     "iopub.status.idle": "2025-12-09T17:13:37.519711Z",
     "shell.execute_reply": "2025-12-09T17:13:37.519111Z",
     "shell.execute_reply.started": "2025-12-09T17:13:37.501411Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6493\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.3175    0.5867    0.4120       467\n",
      "     neutral     0.5145    0.5751    0.5431       925\n",
      "    positive     0.8891    0.6922    0.7784      2281\n",
      "\n",
      "    accuracy                         0.6493      3673\n",
      "   macro avg     0.5737    0.6180    0.5779      3673\n",
      "weighted avg     0.7221    0.6493    0.6726      3673\n",
      "\n",
      "\n",
      "One-vs-Rest AUC:\n",
      "AUC for negative (0): 0.7987\n",
      "AUC for neutral (1): 0.7860\n",
      "AUC for positive (2): 0.8498\n",
      "\n",
      "Confusion Matrix (rows = true, cols = predicted):\n",
      "[[ 274  123   70]\n",
      " [ 266  532  127]\n",
      " [ 323  379 1579]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# 1. Accuracy + classification report\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Accuracy: {acc:.4f}\\n\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred, digits=4, target_names=le.classes_))\n",
    "\n",
    "# 2. One-vs-Rest AUC（正 vs 其他、中 vs 其他、負 vs 其他）\n",
    "print(\"\\nOne-vs-Rest AUC:\")\n",
    "for idx, cls_name in enumerate(le.classes_):\n",
    "    # 這類當成 1，其它類當成 0\n",
    "    y_true_bin = (y_test == idx).astype(int)\n",
    "    auc = roc_auc_score(y_true_bin, y_test_proba[:, idx])\n",
    "    print(f\"AUC for {cls_name} ({idx}): {auc:.4f}\")\n",
    "\n",
    "# 3. Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"\\nConfusion Matrix (rows = true, cols = predicted):\")\n",
    "print(cm)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8959600,
     "sourceId": 14074929,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
