import pandas as pd
import nltk
from nltk.corpus import stopwords
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import LinearSVC
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier



# Step 1: Load the dataset (already cleaned it)
df = pd.read_csv('/kaggle/input/youtube-comments-dataset/YoutubeCommentsDataSet.csv')
df = df.dropna(subset=['Comment'])

# Replace 'neg' with 0, 'pos' with 1, and 'nue' with 2
df['Sentiment'] = df['Sentiment'].replace({'negative': 0, 'neutral': 1, 'positive': 2})

def remove_stopwords(text):
    stop_words = set(stopwords.words('english'))
    words = text.split()
    filtered_words = [word for word in words if word.lower() not in stop_words]
    return ' '.join(filtered_words)

# Example usage
df['Comment'] = df['Comment'].apply(remove_stopwords)
df.head()


# Step 2: Split the data into features (X) and target (y)
X = df['Comment']
y = df['Sentiment']
# Step 3: Split the dataset into training and testing sets (90% train, 10% test)
# random_state=42, test_size=0.1, stratify=y
#因為有六成是正樣本（不平衡）#設定分層split才能保持測試集和訓練/驗證集分佈一樣。
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.1,
    random_state=42,
    stratify=y
)

# 印出 test 的前五筆與總筆數
print("X_test 前五筆：")
print(X_test.head())
print("\n測試集筆數：", len(X_test))

#Step 4: Convert text data into numerical features using TF-IDF Vectorizer
vectorizer = TfidfVectorizer(max_features=5000)
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# Step 5: Initialize models
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Linear SVM": LinearSVC(),
    "Naive Bayes": MultinomialNB(),
    "Random Forest": RandomForestClassifier(n_estimators=200, random_state=42),
    "XGBoost": XGBClassifier(eval_metric='mlogloss', random_state=42)
}







from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    roc_auc_score
)
from sklearn.preprocessing import label_binarize
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

# One-vs-Rest AUC 用的 binarized label
y_test_binarized = label_binarize(y_test, classes=[0, 1, 2])

metrics_dict = {}
auc_dict = {}
cm_dict = {}

test_index = X_test.index
test_text = X_test.values

for model_name, model in models.items():
    print(f"\n================ {model_name} ================")

    model.fit(X_train_tfidf, y_train)

    # 1) 預測 label
    y_pred = model.predict(X_test_tfidf)

    # 2) Accuracy + classification report
    acc = accuracy_score(y_test, y_pred)
    print(f"Accuracy: {acc:.4f}")
    report = classification_report(y_test, y_pred, digits=4, output_dict=True)
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred, digits=4))

    metrics_dict[model_name] = {
        "accuracy": acc,
        "precision_macro": report["macro avg"]["precision"],
        "recall_macro": report["macro avg"]["recall"],
        "f1_macro": report["macro avg"]["f1-score"],
    }

    # 3) One-vs-Rest AUC
    if hasattr(model, "predict_proba"):
        y_score = model.predict_proba(X_test_tfidf)
    else:
        y_score = model.decision_function(X_test_tfidf)
        if y_score.ndim == 1:
            y_score = np.vstack([-y_score, y_score]).T

    auc_per_class = {}
    class_names = ["Negative (0)", "Neutral (1)", "Positive (2)"]
    print("\nOne-vs-Rest AUC:")
    for i, cname in enumerate(class_names):
        auc = roc_auc_score(y_test_binarized[:, i], y_score[:, i])
        auc_per_class[cname] = auc
        print(f"AUC for {cname}: {auc:.4f}")
    auc_dict[model_name] = auc_per_class

    # 4) Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    cm_dict[model_name] = cm
    print("\nConfusion Matrix (rows = true, cols = predicted):")
    print(cm)

    #把預測輸出成 CSV
    pred_df = pd.DataFrame({
        "id": test_index,
        "comment": test_text,
        "true_label": y_test.values,
        "pred_label": y_pred
    })
    filename = model_name.replace(" ", "_").lower() + "_pred.csv"
    pred_df.to_csv(filename, index=False)
    print(f"\nSaved predictions to: {filename}")

